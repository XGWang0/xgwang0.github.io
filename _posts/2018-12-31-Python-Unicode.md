---
layout: post
title:  "Python Unicode"
categories: PYTHON
tags:  unicode
author: Root Wang
---

* content
{:toc}

### 概念
* 字节：计算机数据的表示。8位二进制。可以表示无符号整数：0-255。下文，用`字节流`表示`字节`组成的串。 
* 字符：英文字符`abc`，或者中文字符`你我他`。字符本身不知道如何在计算机中保存。下文中，会避免使用“字符串”这个词，而用`文本`来表示`字符`组成的串。 
* 编码（动词）：按照某种规则（这个规则称为：编码（名词））将`文本`转换为`字节流`。（在python中：str 转成 unicode） 
* 解码（动词）：将`字节流`按照某种规则转换成`文本`。（在python中：unicode 变成 str） 

> 实际上，任何东西在计算机中表示，都需要编码。例如，视频要编码然后保存在文件中，播放的时候需要解码才能观看。 
> unicode：unicode定义了，一个`字符`和一个`数字`的对应，但是并没有规定这个`数字`在计算机中怎么保存。（就像在C中，一个整数既可以是int，也可以是short。unicode没有规定用int还是用short来表示一个`字符`） 
    * utf8：unicode实现。它使用unicode定义的`字符`与`数字`映射，进而规定了，如何在计算机中保存这个数字。其它的utf16等都是unicode实现。 
    > UTF-8 是一种 Unicode 的编码方式，主要作用对 Unicode 码的数据进行转换，转换后方便存储和网络传输
    *gbk：类似utf8这样的`编码`。但是它没有使用unicode定义的`字符`与`数字`映射，而是使用了另一套的映射方法。而且，它还定义了如何在计算机中保存。 

### 字符到编码 
理论上，从一个字符到具体的编码，会经过以下几个概念。 
* 字符集（Abstract character repertoire） 
* 编码字符集（Coded character set） 
* 字符编码方式（Character encoding form） 
* 字符编码方案（Character encoding scheme ） 
字符集：就算一堆抽象的字符，如所有中文。字符集的定义是抽象的，与计算机无关。 
编码字符集：是一个从整数集子集到字符集抽象元素的映射。即给抽象的字符编上数字。如gb2312中的定义的字符，每个字符都有个整数和它对应。一个整数只对应着一个字符。反过来，则不一定是。这里所说的映射关系，是数学意义上的映射关系。编码字符集也是与计算机无关的。unicode字符集也在这一层。 
字符编码方式：这个开始与计算机有关了。编码字符集的编码点在计算机里的具体表现形式。通俗的说，意思就是怎么样才能将字符所对应的整数的放进计算机内存，或文件、或网络中。于是，不同人有不同的实现方式，所谓的万码奔腾，就是指这个。gb2312，utf-8,utf-16,utf-32等都在这一层。 
字符编码方案：这个更加与计算机密切相关。具体是与操作系统密切相关。主要是解决大小字节序的问题。对于UTF-16和UTF-32
编码，Unicode都支持big-endian 和 little-endian两种编码方案。 

一般来说，我们所说的编码，都在第三层完成。具体到一个软件系统中，则很复杂。 
浏览器－apache－tomcat（包括tomcat内部的jsp编码、编译，文件读取）－数据库之间，只要存在数据交互，就有可能发生编码不一致，如果在读取数据时，没有正确的decode和encode，出现乱码就是家常便饭了。

#### encode，decode方法

字符串在Python内部的表示是`Unicode`编码,因此,在做编码转换时,通常需要以`unicode`作为中间编码,即先`将其他编码的字符`解码(decode)成`unicode`,再从`unicode`编码(encode)成`另一种编码`。
* decode的作用是将其他编码的字符转换成unicode编码,如str1,decode('gb2312'),表示将gb2312编码的字符串str1解码成unicode编码。
* encode的作用是将unicode编码转换成其他编码的字符串,如str2,encode('gb2312'),表示将unicode编码的字符串str2编码成gb2312编码。

***因此,转码的时候一定要明白,字符串str是什么编码,然后decode成unicode编码,然后再encode成其他编码。***


#### \#coding=utf8= 
当你在py文件的第一行中，写了这句话，并确实按照这个编码保存了文本的话，那么这句话有以下几个功能。 
1. 使得词法分析器能正常运作，对于注释中的中文不报错了。 
2. 对于u"中文"这样literal string能知道两个引号中的内容是utf8编码的，然后能正确转换成unicode 
3. `中文`对于这样的literal string你会知道，这中间的内容是utf8编码，然后就可以正确转换成其它编码或unicode了。


#### Python编码和Windows控制台 
我发现，很多初学者出错的地方都在print语句，这牵涉到控制台的输出。
首先，Windows的控制台确实是`unicode（utf16_le编码）`的，或者更准确的说使用`字符`为单位输出文本的。 
但是，程序的执行是可以被重定向到文件的，而`文件的单位`是`字节`。 
所以，对于C运行时的函数`printf`之类的，输出必须有一个编码，把`文本`转换成`字节`。可能是为了兼容95，98，没有使用`unicode`的编码，而是`mbcs`（不是gbk之类的）。 

windows的mbcs，也就是ansi，它会在`不同语言`的windows中使用`不同的编码`，在`中文`的windows中就是`gb`系列的编码。 
这造成了同一个文本，在不同语言的windows中是不兼容的。 

现在我们知道了，如果你要在windows的控制台中输出文本，它的编码一定要是“mbcs”。
 
对于python的`unicode`变量，使用`print`输出的话，会使用`sys.getfilesystemencoding()`返回的编码，把它变成str。如果是一个`utf8`编码str变量，那么就需要 `print s.decode('utf8').encode('mbcs')` 
最后，对于`str`变量，`file`文件读取的内容，`urllib`得到的网络上的内容，都是以`字节`形式的。 
它们如果确实是一段`文本`，比如你想print出来看看。那么你必须知道它们的编码。然后decode成unicode。 

如何知道它们的编码： 
1. 事先约定。（比如这个文本文件就是你自己用utf8编码保存的） 
2. 协议。（python文件第一行的#coding=utf8，html中的等） 


虽然`文件`或者`网页`是`文本`的,但是在保存或者传输时已经被编码成`bytes`了,所以用"rb"打开的file和从socket读取的流是基于字节的. ***它们如果确实是一段“文本”，比如你想print出来看看。那么你必须知道它们的编码。然后decode成unicode***
这里的加引号的`"文本"`,其实还是字节流`(bytes)`,而不是真正的`文本(unicode)`,只是说明我们知道他是`可以解码成文本的`.
在解码的时候,如果是基于约定的,那就可以直接从指定地方读取如BOM或者python文件的指定coding或者网页的meta,就可以正确解码, 但是现在很多文件/网页虽然指定了编码,但是文件格式实际却使用了其他的编码(比如py文件指定了coding=utf8,但是你还是可以保存成ansi--记事本的默认编码),这种情况下真实的编码就需要去猜了, 解码了的文本只存在运行环境中,如果你需要打印/保存/输出给数据库/网络传递,就又需要一次编码过程, 这个编码与上面的编码没有关系,只是依赖于你的选择,但是这个编码也不是可以随便选择的,因为编码后的bytes如果又需要传递给其他人/环境,那么如果你的编码也不遵循约定,又给下一个人/环境造成了困扰,于是递归之.

#### Python3 中编码:

* 二进制 -> 转换 -> 字符串 需要解码 decode
* 字符串 -> 转换 -> 二进制 需要编码 encode

python3 内存中使用的`字符串`全部是`unicode码`. There is a bytes type that holds raw bytes.，但是`网络传输的数据`或者`从磁盘读取的数据`是把 unicode 码转换过的数据，通常情况下可能是 `utf-8` 格式的数据，所以如果从`网络中读取`或者`磁盘中读取`其实就是把 `utf-8` 格式的数据`解码`成 `unicode` 码数据，相反如果想把`内存中 unicode 码`数据`存储`到`磁盘或者网络`中需要对 `unicode` 码进行编码，通常可以采用 `utf-8` 的形式进行编码

***python3解释器中自带UTF-8编码器，python2中不自带，所以需要手动设置： #coding:utf-8***

